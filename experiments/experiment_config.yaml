# Experiment Configuration for SLM AFlow Research

experiments:
  # Phase 1: Cross-model validation (run in parallel)
  - id: "qwen_trial1"
    dataset: "GSM8K"
    exec_model: "Qwen/Qwen2.5-3B-Instruct"
    description: "Llama trial 1 - test Qwen 3B model"
    tags: ["phase1", "qwen", "slm"]

  - id: "llama_trial1"
    dataset: "GSM8K"
    exec_model: "meta-llama/Llama-3.2-3B-Instruct"
    description: "Llama trial 1 - test Meta's 3B model"
    tags: ["phase1", "llama", "slm"]

  - id: "phi3_trial1"
    dataset: "GSM8K"
    exec_model: "microsoft/Phi-3-mini-4k-instruct"
    description: "Phi-3 trial 1 - test Microsoft's reasoning model"
    tags: ["phase1", "phi3", "slm"]

  # Phase 2: Add more experiments here based on Phase 1 results
  # Examples (uncomment when ready):
  # - id: "llama_trial2"
  #   dataset: "GSM8K"
  #   exec_model: "meta-llama/Llama-3.2-3B-Instruct"
  #   tags: ["phase2", "llama"]
  #
  # - id: "qwen_trial3"
  #   dataset: "GSM8K"
  #   exec_model: "Qwen/Qwen2.5-3B-Instruct"
  #   tags: ["phase2", "qwen"]

# Default parameters for all experiments
defaults:
  opt_model: "gpt-5.1"
  max_rounds: 20
  sample: 4
  validation_rounds: 3
